{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/whongyi/openrec/blob/master/tutorials/Youtube_Recommender_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWlLsq0c83u9"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src =\"https://recsys.acm.org/wp-content/uploads/2017/07/recsys-18-small.png\" height=\"40\" /> <font size=\"4\">Recsys 2018 Tutorial</font>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <font size=\"4\"><b>Modularizing Deep Neural Network-Inspired Recommendation Algorithms</b></font>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <font size=\"4\">Hands on: Customizing Deep YouTube Video Recommendation. Youtube example</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXV-a9jCQtvh"
   },
   "source": [
    "# the Youtube Recommender\n",
    "\n",
    "The training graph of YouTube-Rec can be decomposed as follows.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec_module.png\" height=\"600\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **inputgraph**: user demographis, item consumption history and the groundtruth label.\n",
    "* **usergraph**: extract user-specific latent factor.\n",
    "* **itemgraph**: extract latent factors for items.\n",
    "* **interactiongraph**: uses MLP and softmax to model user-item interactions.\n",
    "\n",
    "After defining subgraphs, their interfaces and connections need to be specified. A sample specification of YouTube-Rec can be as follows.\n",
    "<p align=\"center\">\n",
    "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec.png\" height=\"300\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fx9f__-hL3C2"
   },
   "source": [
    "# Install OpenRec and download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCPtcmnDKsBH"
   },
   "outputs": [],
   "source": [
    "!pip install openrec\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
    "urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
    "                   'lastfm_test.npy')\n",
    "urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
    "                   'lastfm_train.npy')\n",
    "urllib.request.urlretrieve('%s/lastfm/user_feature.npy' % dataset_prefix, \n",
    "                   'user_feature.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoTTS6s0OJMu"
   },
   "source": [
    "# Your task \n",
    "-  understand reuse and extend an exsiting recommender\n",
    "-  fill in the placeholders in the implementation of the `YouTubeRec` function \n",
    "-  successfully run the experimental code with the recommender you just built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DybVedLuNe_d"
   },
   "outputs": [],
   "source": [
    "from openrec.recommenders import VanillaYouTubeRec  # load the vanilla version and extend it with user demographic informaton\n",
    "from openrec.modules.extractions import LatentFactor\n",
    "from openrec.modules.interactions import MLPSoftmax\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def Tutorial_YouTubeRec(batch_size, user_dict, item_dict, dim_user_embed, dim_item_embed, \n",
    "        max_seq_len, l2_reg_embed=None, l2_reg_mlp=None, dropout=None, \n",
    "        init_model_dir=None, save_model_dir='Youtube/', train=True, serve=False):\n",
    "\n",
    "  \n",
    "    rec = VanillaYouTubeRec(batch_size=batch_size,\n",
    "                            dim_item_embed=dim_item_embed['id'], \n",
    "                            max_seq_len=max_seq_len, \n",
    "                            total_items=item_dict['id'],\n",
    "                            l2_reg_embed=l2_reg_embed, \n",
    "                            l2_reg_mlp=l2_reg_embed, \n",
    "                            dropout=dropout, \n",
    "                            init_model_dir=init_model_dir,\n",
    "                            save_model_dir=save_model_dir, \n",
    "                            train=train, \n",
    "                            serve=serve)\n",
    "    \n",
    "\n",
    "    \n",
    "    @rec.traingraph.inputgraph.extend(outs=['user_gender', 'user_geo'])\n",
    "    def add_train_feature(subgraph):\n",
    "        subgraph['user_gender'] = tf.placeholder(tf.int32, shape=[batch_size], name='user_gender')\n",
    "        subgraph['user_geo'] = tf.placeholder(tf.int32, shape=[batch_size], name='user_geo')\n",
    "       \n",
    "        subgraph.update_global_input_mapping({'user_gender': subgraph['user_gender'],\n",
    "                                              'user_geo': subgraph['user_geo']})\n",
    "\n",
    "        \n",
    "\n",
    "    @rec.servegraph.inputgraph.extend(outs=['user_gender', 'user_geo'])\n",
    "    def add_serve_feature(subgraph):\n",
    "        subgraph['user_gender'] = tf.placeholder(tf.int32, shape=[None], name='user_gender')\n",
    "        subgraph['user_geo'] = tf.placeholder(tf.int32, shape=[None], name='user_geo')\n",
    "\n",
    "        subgraph.update_global_input_mapping({'user_gender': subgraph['user_gender'],\n",
    "                                              'user_geo': subgraph['user_geo']})\n",
    "        \n",
    "    \n",
    "\n",
    "    @rec.traingraph.usergraph(ins=['user_gender', 'user_geo'], outs=['user_vec'])\n",
    "    @rec.servegraph.usergraph(ins=['user_gender', 'user_geo'], outs=['user_vec'])\n",
    "    def user_graph(subgraph):\n",
    "        _, user_gender = LatentFactor(l2_reg=l2_reg_embed,\n",
    "                              shape=[user_dict['gender'], dim_user_embed['gender']],\n",
    "                              id_=subgraph['user_gender'],\n",
    "                              subgraph=subgraph,\n",
    "                              init='normal',\n",
    "                              scope='user_gender')\n",
    "\n",
    "        _, user_geo = LatentFactor(l2_reg=l2_reg_embed,\n",
    "                             shape=[user_dict['geo'], dim_user_embed['geo']],\n",
    "                             id_=subgraph['user_geo'],\n",
    "                             subgraph=subgraph,\n",
    "                             init='normal',\n",
    "                             scope='user_geo')\n",
    "        subgraph['user_vec'] = tf.concat([user_gender, user_geo], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @rec.traingraph.interactiongraph(ins=['user_vec', 'seq_item_vec', 'seq_len', 'label'])\n",
    "    def train_interaction_graph(subgraph):\n",
    "        \n",
    "        MLPSoftmax(user=subgraph['user_vec'],\n",
    "                   item=subgraph['seq_item_vec'],\n",
    "                   seq_len=subgraph['seq_len'],\n",
    "                   max_seq_len=max_seq_len,\n",
    "                   dims=[dim_user_embed['total'] + dim_item_embed['total'], item_dict['id']],\n",
    "                   l2_reg=l2_reg_mlp,\n",
    "                   labels=subgraph['label'],\n",
    "                   dropout=dropout,\n",
    "                   train=True,\n",
    "                   subgraph=subgraph,\n",
    "                   scope='MLPSoftmax')\n",
    "        \n",
    "        \n",
    "\n",
    "    @rec.servegraph.interactiongraph(ins=['user_vec', 'seq_item_vec', 'seq_len'])\n",
    "    def serve_interaction_graph(subgraph):\n",
    "\n",
    "        MLPSoftmax(user=subgraph['user_vec'],\n",
    "                   item=subgraph['seq_item_vec'],\n",
    "                   seq_len=subgraph['seq_len'],\n",
    "                   max_seq_len=max_seq_len,\n",
    "                   dims=[dim_user_embed['total'] + dim_item_embed['total'], item_dict['id']],\n",
    "                   l2_reg=l2_reg_mlp,\n",
    "                   train=False,\n",
    "                   subgraph=subgraph,\n",
    "                   scope='MLPSoftmax') \n",
    "    \n",
    "    \n",
    "    @rec.traingraph.connector.extend\n",
    "    @rec.servegraph.connector.extend\n",
    "    def connect(graph): \n",
    "        graph.usergraph['user_gender'] = graph.inputgraph['user_gender']\n",
    "        graph.usergraph['user_geo'] = graph.inputgraph['user_geo']\n",
    "        graph.interactiongraph['user_vec'] = graph.usergraph['user_vec']\n",
    "\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hxy8mj0xJQ1"
   },
   "source": [
    "# Experiement\n",
    "We will use the recommender you implemented to run a toy experiement on the LastFM dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1hg5H5D9-pO"
   },
   "source": [
    "## load lastfm dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd6iP8xyOA5P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load('lastfm_train.npy')\n",
    "test_data = np.load('lastfm_test.npy')\n",
    "user_feature = np.load('user_feature.npy')\n",
    "\n",
    "total_users = 992   \n",
    "total_items = 14598\n",
    "user_dict = {'gender': 3, \n",
    "             'geo': 67}\n",
    "item_dict = {'id': total_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoox3UQxPCMn"
   },
   "outputs": [],
   "source": [
    "user_feature[:10], test_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOwNJ4QF-MCx"
   },
   "source": [
    "## preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olf0fFSTLUrg"
   },
   "outputs": [],
   "source": [
    "from openrec.utils import Dataset\n",
    "\n",
    "train_dataset = Dataset(train_data, total_users, total_items, \n",
    "                        sortby='ts', name='Train')\n",
    "test_dataset = Dataset(test_data, total_users, total_items, \n",
    "                       sortby='ts', name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ralJgDJb-Gn9"
   },
   "source": [
    "## hyperparameters and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_17lWG_OEhm"
   },
   "outputs": [],
   "source": [
    "dim_user_embed = {'geo': 40,    # dimension of user geographic embedding\n",
    "                  'gender': 10, # dimension of user gender embedding\n",
    "                   'total': 50} \n",
    "dim_item_embed = {'id': 50, 'total': 50}     # dimension of item embedding\n",
    "\n",
    "\n",
    "max_seq_len = 100       # the maxium length of user's listen history\n",
    "total_iter = int(1e3)   # iterations for training \n",
    "batch_size = 100        # training batch size\n",
    "eval_iter = 100         # iteration of evaluation\n",
    "save_iter = eval_iter   # iteration of saving model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJdIPZZf-Qx2"
   },
   "source": [
    "## define sampler\n",
    "We use `YouTubeSampler`  and `YouTubeEvaluationSampler` to sample sequences of training and testing samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzlKCqgyPRyp"
   },
   "outputs": [],
   "source": [
    "from openrec.utils.samplers import YouTubeSampler, YouTubeEvaluationSampler\n",
    "  \n",
    "train_sampler = YouTubeSampler(user_feature=user_feature, \n",
    "                                batch_size=batch_size, \n",
    "                                max_seq_len=max_seq_len, \n",
    "                                dataset=train_dataset, \n",
    "                                num_process=1)\n",
    "test_sampler = YouTubeEvaluationSampler(user_feature=user_feature, \n",
    "                              dataset=test_dataset, \n",
    "                               max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ucqUtRd-YZN"
   },
   "source": [
    "## define evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzKk_8lW7Wwf"
   },
   "outputs": [],
   "source": [
    "from openrec.utils.evaluators import AUC, Recall\n",
    "\n",
    "auc_evaluator = AUC()\n",
    "recall_evaluator = Recall(recall_at=[100, 200, 300, 400, 500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5w04YyoE-UEm"
   },
   "source": [
    "## define model trainer\n",
    "\n",
    "we used the Vanilla version of the Youtube recommender to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWX0XpnT7RBE"
   },
   "outputs": [],
   "source": [
    "from openrec import ModelTrainer\n",
    "\n",
    "model = Tutorial_YouTubeRec(batch_size=batch_size,\n",
    "                            user_dict=user_dict,\n",
    "                            item_dict=item_dict,\n",
    "                            max_seq_len=max_seq_len,\n",
    "                            dim_item_embed=dim_item_embed,\n",
    "                            dim_user_embed=dim_user_embed,\n",
    "                            save_model_dir='youtube_recommender/',\n",
    "                            train=True, serve=True)\n",
    "\n",
    "model_trainer = ModelTrainer(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwKd_iFB-thk"
   },
   "source": [
    "## training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-UffgZW7Rp9"
   },
   "outputs": [],
   "source": [
    "model_trainer.train(total_iter=total_iter, \n",
    "                    eval_iter=eval_iter,\n",
    "                    save_iter=save_iter,\n",
    "                    train_sampler=train_sampler,\n",
    "                    eval_samplers=[test_sampler], \n",
    "                    evaluators=[auc_evaluator, recall_evaluator])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Youtube Recommender example.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
